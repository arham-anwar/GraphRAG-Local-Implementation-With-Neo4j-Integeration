{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\n", "source": "Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"YAXLEY\\\"\"\nDescription List: [\"\\\"The other man who appears in the lane, has a blunt face, and speaks about a tricky task and the Dark Lord.\\\">\", \"\\\"Yaxley is a character assigned a seat beside Dolohov by Voldemort, possibly holding a significant role or relationship.\\\"\", \"\\\"Yaxley is a character who walks with Snape towards the drawing room, hesitates for a moment on the threshold, and eventually enters the room.\\\"\", \"\\\"Yaxley is a person mentioned in the text, arriving late to a meeting and seated beside Dolohov per Voldemort's instructions.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error executing verb \"summarize_descriptions\" in create_summarized_entities: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/datashaper/workflow/workflow.py\", line 415, in _execute_verb\n    result = await result\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 183, in summarize_descriptions\n    results = [\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 184, in <listcomp>\n    await get_resolved_entities(row, semaphore) for row in output.itertuples()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 147, in get_resolved_entities\n    results = await asyncio.gather(*futures)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 167, in do_summarize_descriptions\n    results = await strategy_exec(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/strategies/graph_intelligence/run_graph_intelligence.py\", line 34, in run\n    return await run_summarize_descriptions(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/strategies/graph_intelligence/run_graph_intelligence.py\", line 67, in run_summarize_descriptions\n    result = await extractor(items=items, descriptions=descriptions)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/graph/extractors/summarize/description_summary_extractor.py\", line 73, in __call__\n    result = await self._summarize_descriptions(items, descriptions)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/graph/extractors/summarize/description_summary_extractor.py\", line 106, in _summarize_descriptions\n    result = await self._summarize_descriptions_with_llm(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/graph/extractors/summarize/description_summary_extractor.py\", line 125, in _summarize_descriptions_with_llm\n    response = await self._llm(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\n", "source": "Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}", "details": null}
{"type": "error", "data": "Error running pipeline!", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/run.py\", line 323, in run_pipeline\n    result = await workflow.run(context, callbacks)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/datashaper/workflow/workflow.py\", line 369, in run\n    timing = await self._execute_verb(node, context, callbacks)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/datashaper/workflow/workflow.py\", line 415, in _execute_verb\n    result = await result\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 183, in summarize_descriptions\n    results = [\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 184, in <listcomp>\n    await get_resolved_entities(row, semaphore) for row in output.itertuples()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 147, in get_resolved_entities\n    results = await asyncio.gather(*futures)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 167, in do_summarize_descriptions\n    results = await strategy_exec(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/strategies/graph_intelligence/run_graph_intelligence.py\", line 34, in run\n    return await run_summarize_descriptions(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/strategies/graph_intelligence/run_graph_intelligence.py\", line 67, in run_summarize_descriptions\n    result = await extractor(items=items, descriptions=descriptions)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/graph/extractors/summarize/description_summary_extractor.py\", line 73, in __call__\n    result = await self._summarize_descriptions(items, descriptions)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/graph/extractors/summarize/description_summary_extractor.py\", line 106, in _summarize_descriptions\n    result = await self._summarize_descriptions_with_llm(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/graph/extractors/summarize/description_summary_extractor.py\", line 125, in _summarize_descriptions_with_llm\n    response = await self._llm(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\n", "source": "Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}", "details": null}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\n", "source": "Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: [\"\\\"YAXLEY\\\"\", \"\\\"DOLOHOV\\\"\"]\nDescription List: [\"\\\"Yaxley is assigned a seat beside Dolohov by Voldemort, indicating a possible relationship or role.\\\"\", \"\\\"Yaxley is seated next to Dolohov at the meeting.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\n", "source": "Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"VOLDEMORT\\\"\"\nDescription List: [\"\\\"Voldemort is a character who assigns seats to Severus and Yaxley, demonstrating leadership or authority.\\\"\", \"\\\"Voldemort is a person mentioned in the text, hosting a meeting and addressing Snape and Yaxley.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\n", "source": "Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"DOLOHOV\\\"\"\nDescription List: [\"\\\"Dolohov is a character mentioned in relation to Yaxley, possibly holding a significant role or relationship.\\\"\", \"\\\"Dolohov is a person mentioned in the text, present at the meeting and seated next to Yaxley.\\\"\"]\n#######\nOutput:\n"}}
