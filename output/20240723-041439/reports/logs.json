{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 284. Please try again in 9m53.044s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 284. Please try again in 9m53.044s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"HUMANS\\\"\"\nDescription List: [\"\\\"Humans are a species characterized by intricate hand movements, tool production, and an upright gait.\\\">\", \"\\\"Humans are a species with extraordinarily large brains compared to other animals, with an average brain size ranging from 1,200-1,400 cubic centimeters.\\\"\", \"\\\"humans are a species that have existed for approximately 2.5 million years and have undergone significant progress and development during the Agricultural and Scientific Revolutions.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 233. Please try again in 9m52.432s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 233. Please try again in 9m52.432s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"INDONESIA\\\"\"\nDescription List: [\"\\\"Indonesia is a region with steaming jungles, where human populations evolved distinct traits for survival.\\\"\", \"\\\"Indonesia is mentioned as having steaming jungles where different traits were required for survival compared to northern Europe.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 230. Please try again in 9m52.396s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 230. Please try again in 9m52.396s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"CHIMPANZEES\\\"\"\nDescription List: [\"\\\"Chimpanzees are one of the closest living relatives to humans, sharing a common ancestor just 6 million years ago.\\\"\", \"\\\"Chimpanzees are the closest living relatives of Homo sapiens, sharing a common ancestor 6 million years ago.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 238. Please try again in 9m52.492s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 238. Please try again in 9m52.492s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"GREAT APES\\\"\"\nDescription List: [\"\\\"Great Apes is a family that includes humans, chimpanzees, gorillas, and orangutans.\\\"\", \"\\\"The great apes is a collective term for a group of primates that includes humans, chimpanzees, gorillas, and orang-utans, indicating their close evolutionary relationship.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 209. Please try again in 9m52.141s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 209. Please try again in 9m52.141s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"ASIA\\\"\"\nDescription List: [\"\\\"Asia is a continent where human evolution occurred.\\\"\", \"\\\"Asia is mentioned as one of the areas settled by some of the archaic humans from East Africa.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 210. Please try again in 9m52.153s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 210. Please try again in 9m52.153s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"EUROPE\\\"\"\nDescription List: [\"\\\"Europe is a continent where human evolution occurred.\\\"\", \"\\\"Europe is mentioned as one of the areas settled by some of the archaic humans from East Africa.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 233. Please try again in 9m52.428s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 233. Please try again in 9m52.428s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"HOMO ERECTUS\\\"\"\nDescription List: [\"\\\"Homo erectus is a human species that evolved in East Asia and survived for close to 2 million years.\\\"\", \"\\\"Homo erectus, also known as 'Upright Man', is an ancient human species that survived for close to 2 million years in certain regions.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 237. Please try again in 9m52.476s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 237. Please try again in 9m52.476s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: [\"\\\"HOMO SAPIENS\\\"\", \"\\\"EAST AFRICA\\\"\"]\nDescription List: [\"\\\"East Africa is the region where Homo sapiens, the species to which humans currently belong, evolved.\\\"\", \"\\\"Homo sapiens evolved in East Africa, indicating a geographical connection.\\\"\", \"\\\"Homo sapiens originally evolved in East Africa.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 399. Please try again in 9m54.423s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 399. Please try again in 9m54.423s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"HOMO SAPIENS\\\"\"\nDescription List: [\"\\\"Homo sapiens is a species known for its large brain and high energy consumption at rest.\\\"\", \"\\\"Homo sapiens is a species that currently exists and is referred to as 'Sapiens' in the text.\\\"\", \"\\\"Homo sapiens is the species of the genus Homo, and a member of the family of great apes.\\\"\", \"\\\"Homo sapiens is the species that formed elaborate structures called cultures, leading to the development of history.\\\"\", \"\\\"Homo sapiens is the species to which modern humans belong, and it has kept a secret about its uncivilized cousins and former siblings.\\\"\", \"\\\"Homo sapiens, also known as 'Wise Man', is the species to which humans currently belong.\\\"\", \"\\\"Homo sapiens, also known as modern humans, are unlikely to survive for 2 million years, given the uncertainty of their existence a thousand years from now.\\\"\", \"\\\"Homo sapiens, also named 'Wise Man', is the human species that includes modern humans.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 217. Please try again in 9m52.236s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 217. Please try again in 9m52.236s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: [\"\\\"EAST AFRICA\\\"\", \"\\\"HOMO ERGASTER\\\"\"]\nDescription List: [\"\\\"East Africa is the region where Homo ergaster, a human species, evolved.\\\"\", \"\\\"Homo ergaster evolved in East Africa, indicating a geographical connection.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 227. Please try again in 9m52.356s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 227. Please try again in 9m52.356s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"MODERN SAPIENS\\\"\"\nDescription List: [\"\\\"Modern Sapiens are a group of current humans with brains averaging 1,200-1,400 cubic centimeters.\\\"\", \"\\\"Modern Sapiens refers to the current human species, with a brain size averaging 1,200-1,400 cubic centimeters.\\\">\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54135, Requested 223. Please try again in 9m52.306s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54135, Requested 223. Please try again in 9m52.306s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"HOMO ERGASTER\\\"\"\nDescription List: [\"\\\"Homo ergaster, also known as 'Working Man', is a human species that evolved in East Africa.\\\"\", \"\\\"Homo ergaster, also known as 'Working Man', is one of the human species that evolved in East Africa.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 217. Please try again in 9m52.236s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 217. Please try again in 9m52.236s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"FLORES\\\"\"\nDescription List: [\"\\\"Flores is a small Indonesian island where archaic humans underwent a process of dwarfing.\\\"\", \"\\\"Flores is an island where a unique species of dwarf humans, Homo oresiensis, evolved.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54135, Requested 228. Please try again in 9m52.365s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54135, Requested 228. Please try again in 9m52.365s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"HOMO SOLOENSIS\\\"\"\nDescription List: [\"\\\"Homo soloensis, also known as 'Man from the Solo Valley', was an ancient human species adapted to life in the tropics.\\\"\", \"\\\"Homo soloensis, or Java Man, is a human species that lived on the island of Java, Indonesia.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54135, Requested 248. Please try again in 9m52.606s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54135, Requested 248. Please try again in 9m52.606s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"HOMO RUDOLFENSIS\\\"\"\nDescription List: [\"\\\"Homo rudolfensis is a human species that evolved in East Africa.\\\"\", \"\\\"Homo rudolfensis, also known as 'Man from Lake Rudolf', is a human species that evolved in East Africa.\\\"\", \"\\\"Homo rudolfensis, also known as 'Man from Lake Rudolf', is one of the human species that evolved in East Africa.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54135, Requested 219. Please try again in 9m52.259s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54135, Requested 219. Please try again in 9m52.259s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: [\"\\\"EAST AFRICA\\\"\", \"\\\"HOMO RUDOLFENSIS\\\"\"]\nDescription List: [\"\\\"East Africa is the region where Homo rudolfensis, a human species, evolved.\\\"\", \"\\\"Homo rudolfensis evolved in East Africa, indicating a geographical connection.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 259. Please try again in 9m52.74s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54136, Requested 259. Please try again in 9m52.74s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"EAST AFRICA\\\"\"\nDescription List: [\"\", \"\\\"East Africa is a geographical region where humans and other organisms have inhabited for millions of years.\\\"\", \"\\\"East Africa is a region specifically mentioned as the 'cradle of humanity' where human evolution continued and new species emerged.\\\"\", \"\\\"East Africa is mentioned as the original homeland of Homo sapiens and Australopithecus.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54020, Requested 399. Please try again in 9m53.029s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54020, Requested 399. Please try again in 9m53.029s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"HOMO SAPIENS\\\"\"\nDescription List: [\"\\\"Homo sapiens is a species known for its large brain and high energy consumption at rest.\\\"\", \"\\\"Homo sapiens is a species that currently exists and is referred to as 'Sapiens' in the text.\\\"\", \"\\\"Homo sapiens is the species of the genus Homo, and a member of the family of great apes.\\\"\", \"\\\"Homo sapiens is the species that formed elaborate structures called cultures, leading to the development of history.\\\"\", \"\\\"Homo sapiens is the species to which modern humans belong, and it has kept a secret about its uncivilized cousins and former siblings.\\\"\", \"\\\"Homo sapiens, also known as 'Wise Man', is the species to which humans currently belong.\\\"\", \"\\\"Homo sapiens, also known as modern humans, are unlikely to survive for 2 million years, given the uncertainty of their existence a thousand years from now.\\\"\", \"\\\"Homo sapiens, also named 'Wise Man', is the human species that includes modern humans.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54017, Requested 233. Please try again in 9m51.009s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54017, Requested 233. Please try again in 9m51.009s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"HOMO ERECTUS\\\"\"\nDescription List: [\"\\\"Homo erectus is a human species that evolved in East Asia and survived for close to 2 million years.\\\"\", \"\\\"Homo erectus, also known as 'Upright Man', is an ancient human species that survived for close to 2 million years in certain regions.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error executing verb \"summarize_descriptions\" in create_summarized_entities: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54020, Requested 399. Please try again in 9m53.029s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/datashaper/workflow/workflow.py\", line 415, in _execute_verb\n    result = await result\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 183, in summarize_descriptions\n    results = [\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 184, in <listcomp>\n    await get_resolved_entities(row, semaphore) for row in output.itertuples()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 147, in get_resolved_entities\n    results = await asyncio.gather(*futures)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 167, in do_summarize_descriptions\n    results = await strategy_exec(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/strategies/graph_intelligence/run_graph_intelligence.py\", line 34, in run\n    return await run_summarize_descriptions(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/strategies/graph_intelligence/run_graph_intelligence.py\", line 67, in run_summarize_descriptions\n    result = await extractor(items=items, descriptions=descriptions)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/graph/extractors/summarize/description_summary_extractor.py\", line 73, in __call__\n    result = await self._summarize_descriptions(items, descriptions)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/graph/extractors/summarize/description_summary_extractor.py\", line 106, in _summarize_descriptions\n    result = await self._summarize_descriptions_with_llm(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/graph/extractors/summarize/description_summary_extractor.py\", line 125, in _summarize_descriptions_with_llm\n    response = await self._llm(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54020, Requested 399. Please try again in 9m53.029s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54020, Requested 399. Please try again in 9m53.029s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": null}
{"type": "error", "data": "Error running pipeline!", "stack": "Traceback (most recent call last):\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/run.py\", line 323, in run_pipeline\n    result = await workflow.run(context, callbacks)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/datashaper/workflow/workflow.py\", line 369, in run\n    timing = await self._execute_verb(node, context, callbacks)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/datashaper/workflow/workflow.py\", line 415, in _execute_verb\n    result = await result\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 183, in summarize_descriptions\n    results = [\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 184, in <listcomp>\n    await get_resolved_entities(row, semaphore) for row in output.itertuples()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 147, in get_resolved_entities\n    results = await asyncio.gather(*futures)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/description_summarize.py\", line 167, in do_summarize_descriptions\n    results = await strategy_exec(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/strategies/graph_intelligence/run_graph_intelligence.py\", line 34, in run\n    return await run_summarize_descriptions(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/verbs/entities/summarize/strategies/graph_intelligence/run_graph_intelligence.py\", line 67, in run_summarize_descriptions\n    result = await extractor(items=items, descriptions=descriptions)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/graph/extractors/summarize/description_summary_extractor.py\", line 73, in __call__\n    result = await self._summarize_descriptions(items, descriptions)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/graph/extractors/summarize/description_summary_extractor.py\", line 106, in _summarize_descriptions\n    result = await self._summarize_descriptions_with_llm(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/index/graph/extractors/summarize/description_summary_extractor.py\", line 125, in _summarize_descriptions_with_llm\n    response = await self._llm(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/tenacity/__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/arham/anaconda3/envs/DataScience/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54020, Requested 399. Please try again in 9m53.029s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `mixtral-8x7b-32768` in organization `org_01j2x2pcgvf4b86nkvqy22pbbm` on tokens per minute (TPM): Limit 5000, Used 54020, Requested 399. Please try again in 9m53.029s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}", "details": null}
